{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dacon/anaconda3/envs/py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rows = 13,711, Max sequence length = 1024\n"
     ]
    }
   ],
   "source": [
    "# 데이터 최대 길이 확인\n",
    "max_seq_len = df[\"seq\"].str.len().max()\n",
    "print(f\"✅ Rows = {len(df):,}, Max sequence length = {max_seq_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"InstaDeepAI/nucleotide-transformer-v2-500m-multi-species\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "model = model.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CAP = tokenizer.model_max_length \n",
    "EFFECTIVE_MAX_LEN = min(MODEL_CAP, max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.ids  = df[\"ID\"].tolist()\n",
    "        self.seqs = df[\"seq\"].tolist()\n",
    "        self.tok  = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"ID\": self.ids[idx], \"seq\": self.seqs[idx]}\n",
    "\n",
    "def collate_fn(batch, tok=tokenizer, max_len=EFFECTIVE_MAX_LEN):\n",
    "    ids  = [b[\"ID\"] for b in batch]\n",
    "    seqs = [b[\"seq\"] for b in batch]\n",
    "    enc  = tok.batch_encode_plus(\n",
    "        seqs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\",          \n",
    "        truncation=True,\n",
    "        max_length=max_len\n",
    "    )\n",
    "    # attention_mask: pad 토큰이 0\n",
    "    return {\n",
    "        \"ids\": ids,\n",
    "        \"input_ids\": enc[\"input_ids\"],\n",
    "        \"attention_mask\": enc[\"attention_mask\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataloader ready.\n"
     ]
    }
   ],
   "source": [
    "dataset = SeqDataset(df, tokenizer, EFFECTIVE_MAX_LEN)\n",
    "loader  = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                     num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "print(\"✅ Dataloader ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding shape = 13711 x 1024\n"
     ]
    }
   ],
   "source": [
    "all_ids = []\n",
    "all_embs = []\n",
    "use_amp = (DEVICE == \"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attn_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=use_amp):\n",
    "            outs = model(\n",
    "                input_ids,\n",
    "                attention_mask=attn_mask,\n",
    "                encoder_attention_mask=attn_mask,   \n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "            # 마지막 히든스테이트: (B, L, H)\n",
    "            last_hidden = outs.hidden_states[-1]    # torch.Tensor\n",
    "\n",
    "            # mask 모양 맞추기: (B, L, 1)\n",
    "            mask_exp = attn_mask.unsqueeze(-1)      # 1 for valid tokens\n",
    "\n",
    "            # 패딩 제외 평균: sum(hidden * mask) / sum(mask)\n",
    "            summed = (last_hidden * mask_exp).sum(dim=1)                    # (B, H)\n",
    "            counts = mask_exp.sum(dim=1).clamp(min=1)                       # (B, 1)\n",
    "            seq_emb = summed / counts                                       # (B, H)\n",
    "\n",
    "        all_ids.extend(batch[\"ids\"])\n",
    "        all_embs.append(seq_emb.detach().cpu())\n",
    "\n",
    "emb = torch.vstack(all_embs).float()        # (N, H)\n",
    "N, H = emb.shape\n",
    "print(f\"✅ Embedding shape = {N} x {H}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(data_path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_np = emb.numpy()\n",
    "emb_cols = [f\"emb_{i:04d}\" for i in range(emb_np.shape[1])]\n",
    "emb_df = pd.DataFrame(emb_np, columns=emb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([sample_submission['ID'], emb_df], axis=1)\n",
    "submission.to_csv('baseline_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seohee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
